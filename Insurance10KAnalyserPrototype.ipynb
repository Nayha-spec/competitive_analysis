{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7af9d-92a1-403d-b4db-a001a304958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain pypdf gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34a40f9-0044-4a36-8f9e-368fa9e52350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your environment variables\n",
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89723be8-453d-4211-90f5-63859dfa0515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "class InsuranceAnalyzer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the insurance analysis system with LangChain components\"\"\"\n",
    "        # Initialize OpenAI API key\n",
    "        os.environ['OPENAI_API_KEY'] = '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'  # Replace with your API key\n",
    "        \n",
    "        # Initialize embedding model and text splitter\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        self.vectorstore = None\n",
    "        self.qa_chain = None\n",
    "        \n",
    "        # Load documents on initialization\n",
    "        self.load_documents()\n",
    "\n",
    "    def load_documents(self):\n",
    "        \"\"\"Load and process insurance company filings\"\"\"\n",
    "        try:\n",
    "            documents = []\n",
    "            filings = {\n",
    "                \"Travelers\": \"./10KFilings/travelers_10k_2024.pdf\",\n",
    "                \"Progressive\": \"./10KFilings/progressive_10k_2024.pdf\",\n",
    "                \"Chubb\": \"./10KFilings/chubb_10k_2024.pdf\",\n",
    "                \"Allstate\": \"./10KFilings/allstate_10k_2024.pdf\"\n",
    "            }\n",
    "            \n",
    "            for company, path in filings.items():\n",
    "                loader = PyPDFLoader(path)\n",
    "                docs = loader.load()\n",
    "                chunks = self.text_splitter.split_documents(docs)\n",
    "                \n",
    "                # Add company metadata\n",
    "                for chunk in chunks:\n",
    "                    chunk.metadata['company'] = company\n",
    "                \n",
    "                documents.extend(chunks)\n",
    "\n",
    "            # Create vector store and QA chain\n",
    "            self.vectorstore = Chroma.from_documents(documents, self.embeddings)\n",
    "            \n",
    "            llm = ChatOpenAI(temperature=0)\n",
    "            self.qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=self.vectorstore.as_retriever()\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading documents: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def process_question(self, question):\n",
    "        \"\"\"Process a question about the insurance filings\"\"\"\n",
    "        if not self.qa_chain:\n",
    "            return \"System is not initialized. Please try again.\"\n",
    "            \n",
    "        try:\n",
    "            # Create a prompt that encourages detailed answers\n",
    "            prompt = f\"\"\"\n",
    "            Question: {question}\n",
    "            \n",
    "            Please provide a detailed answer based on the 10-K filings. \n",
    "            If the question mentions specific companies, focus on those companies.\n",
    "            If no companies are specified, consider information from all companies.\n",
    "            Include relevant quotes or data points from the filings when possible.\n",
    "            If you don't have the information the topic the question mention, suggest the user to add financial statement from prior years\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.qa_chain.run(prompt)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return f\"Error processing question: {str(e)}\"\n",
    "\n",
    "# Initialize the analyzer\n",
    "analyzer = InsuranceAnalyzer()\n",
    "\n",
    "def analyze_insurance_query(question):\n",
    "    \"\"\"Gradio interface function to process insurance queries\"\"\"\n",
    "    if not question.strip():\n",
    "        return \"Please enter a question.\"\n",
    "    return analyzer.process_question(question)\n",
    "\n",
    "# Create the Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=analyze_insurance_query,\n",
    "    inputs=[\n",
    "        gr.Textbox(\n",
    "            label=\"Ask a question about insurance companies\",\n",
    "            placeholder=\"E.g., What are the biggest strategic initiatives for Allstate?\",\n",
    "            lines=3\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(\n",
    "            label=\"Analysis Result\",\n",
    "            lines=10\n",
    "        )\n",
    "    ],\n",
    "    title=\"Insurance Competitor Analysis\",\n",
    "    description=\"\"\"Analyze competitors' financial statements and strategic initiatives.\n",
    "    Available companies: Travelers, Progressive, Chubb, Allstate\"\"\",\n",
    "    examples=[\n",
    "        [\"What are the causes driving the largest amount of losses across all carriers?\"],\n",
    "        [\"What are the biggest strategic initiatives for Allstate?\"],\n",
    "        [\"Compare Traveler's Strategic initiatives with Chubb's\"]\n",
    "    ],\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42acfd0-7c5f-4bf9-967e-73cb46ed0112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
